/scratch/pm2758/distTraining/Code/mp_dist_trial.py:59: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  log_probs = F.log_softmax(y)
/scratch/pm2758/anaconda3/envs/pytorch_v1/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/scratch/pm2758/distTraining/Code/mp_dist_trial.py:59: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  log_probs = F.log_softmax(y)
/scratch/pm2758/anaconda3/envs/pytorch_v1/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/scratch/pm2758/distTraining/Code/mp_dist_trial.py:59: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  log_probs = F.log_softmax(y)
/scratch/pm2758/anaconda3/envs/pytorch_v1/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/scratch/pm2758/distTraining/Code/mp_dist_trial.py:59: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  log_probs = F.log_softmax(y)
/scratch/pm2758/anaconda3/envs/pytorch_v1/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
Traceback (most recent call last):
  File "mp_dist_trial.py", line 303, in <module>
    run_demo(setupAndCall, 4)
  File "mp_dist_trial.py", line 299, in run_demo
    join=True)
  File "/scratch/pm2758/anaconda3/envs/pytorch_v1/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 167, in spawn
    while not spawn_context.join():
  File "/scratch/pm2758/anaconda3/envs/pytorch_v1/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 114, in join
    raise Exception(msg)
Exception: 

-- Process 2 terminated with the following error:
Traceback (most recent call last):
  File "/scratch/pm2758/anaconda3/envs/pytorch_v1/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 19, in _wrap
    fn(i, *args)
  File "/scratch/pm2758/distTraining/Code/mp_dist_trial.py", line 278, in setupAndCall
    main(rank, world_size)
  File "/scratch/pm2758/distTraining/Code/mp_dist_trial.py", line 250, in main
    weighted_loss, numberOfSamples, average_time = run(rank, wsize, model, optimizer, criterion, epochs, trainLoader, bszTrain, devLoader, use_cuda, batchSize, batchSize, 100)
  File "/scratch/pm2758/distTraining/Code/mp_dist_trial.py", line 196, in run
    print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\tDev Loss: {:.6f}\tDev Acc: {:.6f}'.format(epoch, batch_idx * len(data), len(trainLoader.dataset), 100. * batch_idx / len(trainLoader), loss.data[0], dev_loss.data[0], dev_acc))
IndexError: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number

